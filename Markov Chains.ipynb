{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains\n",
    "\n",
    "The idea is to build a table that captures the words after a specific word, but we also need the probability for each word. So a double dictionary? Or we can just save all the words, repeating them, that in the end is like a probability. This is space iniefficient, but it is fine for the first approach. \n",
    "\n",
    "Inspired from: http://www.cyber-omelette.com/2017/01/markov.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-9bcef0895fae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#     print(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-9bcef0895fae>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, length)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mcurrent_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mlist_of_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m#         print(list_of_words)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_of_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Function that creates the dictionary with the words and frequencies\n",
    "def generate_model(text):\n",
    "    i=0\n",
    "    chain={}\n",
    "    words=text.split()\n",
    "    max_length = len(words)\n",
    "    for word in words:        \n",
    "        # Checking for the end of the phrase\n",
    "        if ((i+1) < max_length):\n",
    "            if word in chain:\n",
    "                chain[word].append(words[i+1])\n",
    "            else:\n",
    "                chain[word] = [words[i+1]]\n",
    "            i+=1\n",
    "        else:\n",
    "            chain[word] = [\"\"]\n",
    "    return chain\n",
    "   \n",
    "# Function that generates the text. Question is: Where do we start? \n",
    "# Let's start with a random word. Then we can change that. \n",
    "def generate_text(model, length):\n",
    "    initial_state=list(model)[random.randint(0,len(model)-1)]\n",
    "    text=[initial_state]\n",
    "    current_state=initial_state\n",
    "    for i in range(0,length-1):\n",
    "        list_of_words = model[current_state]\n",
    "#         print(list_of_words)\n",
    "        word = list_of_words[random.randint(0,len(list_of_words)-1)]\n",
    "        text.append(word)\n",
    "        current_state=word\n",
    "    return text\n",
    "  \n",
    "def read_file(file):\n",
    "    with open(file, 'r') as myfile:\n",
    "        data = myfile.read().replace(',', ' ')\n",
    "        data=data.replace('\\n','')\n",
    "        data=data.replace('.','')\n",
    "#         print(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "text = read_file(\"federici.txt\")\n",
    "# print(text)\n",
    "if __name__ == \"__main__\":\n",
    "    model = generate_model(text)\n",
    "#     print(model)\n",
    "    generated_text = generate_text(model,40)\n",
    "    print(\" \".join(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Le', 'mie', 'pauresono', 'carezze', 'mancateincertezze', 'che', 'tornano', 'a', 'un', 'passo', 'da', 'meevitando', 'i', 'rumorisono', 'mio', 'padre', 'e', 'suoi', 'erroriun', 'bersaglio', 'sfioratole', 'paure', 'sentocome', 'distanze', 'centrosono', \"l'amore\", 'ho', 'dentroe', 'non', 'so', 'controllareil', 'primo', 'giorno', 'di', 'scuola', 'piccolo', 'uomoche', 'ha', 'vergogna', 'parlarele', 'riflessioni', 'sospeseun', 'mattino', 'alle', 'settele', 'sento', 'qui', 'dentro', 'mesono', 'parole', 'mai', 'detteTu', 'tu', 'mi', 'hai', 'voluto', 'crederesono', 'anni', 'ti', 'aspettoe', 'ora', 'riesco', 'respirare', 'piùora', 'basta', 'devi', 'sceglieresono', 'aspettole', 'bugiardo', 'giuratutte', 'le', 'cose', 'persotenendo', 'ugualmente', 'una', 'stretta', 'sicurala', 'prima', 'volta', 'dettoho', 'bisogno', 'tesono', 'quel', 'dubbio', 'resta', 'nascostoanche', 'quando', 'capito', 'perchéperchéTu', 'aspettoCi', 'sono', 'più', 'dimenticaresono', 'stesse', 'imparato', 'capirele', 'convinzioni', 'saranno', 'sempre', 'ugualineanche', 'quelle', 'oggi', 'sembrano', 'normalila', 'differenza', 'fra', 'ogni', 'uomo', 'sta', \"nell'intenzionee\", 'posso', 'aspettosono', 'aspetto'])\n"
     ]
    }
   ],
   "source": [
    "print(model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Felisa'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "print(random.randint(0, 2))\n",
    "\n",
    "d = {\"Eva\":1, \"Angel\":[1,2,3], \"Felisa\":3}\n",
    "print(len(d))\n",
    "list(d)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
