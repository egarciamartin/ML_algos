{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains\n",
    "\n",
    "The idea is to build a table that captures the words after a specific word, but we also need the probability for each word. So a double dictionary? Or we can just save all the words, repeating them, that in the end is like a probability. This is space iniefficient, but it is fine for the first approach. \n",
    "\n",
    "Inspired from: http://www.cyber-omelette.com/2017/01/markov.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1978). Pero la Iglesia veía todavia estas circunstancias en el cuerpo del ingreso del pensamiento judío produjo un campo metafórico en el mundo visible sino que se creó un desafío que tanto supone podrían tener éxito debido a campesinos también\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Function that creates the dictionary with the words and frequencies\n",
    "def generate_model(text):\n",
    "    i=0\n",
    "    chain={}\n",
    "    words=text.split()\n",
    "    max_length = len(words)\n",
    "    for word in words:        \n",
    "        # Checking for the end of the text\n",
    "        if ((i+1) < max_length):\n",
    "            if word in chain:\n",
    "                chain[word].append(words[i+1])\n",
    "            else:\n",
    "                chain[word] = [words[i+1]]\n",
    "            i+=1\n",
    "        else:\n",
    "            chain[word] = [\"\"]\n",
    "    return chain\n",
    "   \n",
    "# Function that generates the text. Question is: Where do we start? \n",
    "# Let's start with a random word. Then we can change that. \n",
    "def generate_text(model, length):\n",
    "    initial_state=list(model)[random.randint(0,len(model)-1)]\n",
    "    text=[initial_state]\n",
    "    current_state=initial_state\n",
    "    for i in range(0,length-1):\n",
    "        list_of_words = model[current_state]\n",
    "#         print(list_of_words)\n",
    "        word = list_of_words[random.randint(0,len(list_of_words)-1)]\n",
    "        text.append(word)\n",
    "        current_state=word\n",
    "    return text\n",
    "  \n",
    "def read_file(file):\n",
    "    with open(file, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "        data=data.replace(',', '')\n",
    "        data=data.replace('\\n',' ')\n",
    "        data=data.replace('   ', ' ')\n",
    "    return data\n",
    "\n",
    "\n",
    "text = read_file(\"federici.txt\")\n",
    "if __name__ == \"__main__\":\n",
    "    model = generate_model(text)\n",
    "#     print(model)\n",
    "    generated_text = generate_text(model,40)\n",
    "    print(\" \".join(generated_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
